# envshield/core/importer.py
import os
import re
from typing import Dict, Any, Tuple

import toml
import questionary
from rich.console import Console

from .scanner import SECRET_PATTERNS
from ..parsers.factory import get_parser
from .exceptions import EnvShieldException

console = Console()

# Heuristics for smarter import
SECRET_KEY_KEYWORDS = ["secret", "token", "password", "key", "auth", "credential"]
COMMON_NON_SECRETS = {
    "DEBUG": ["true", "false"],
    "LOG_LEVEL": ["info", "debug", "warning", "error", "critical"],
    "ENV": ["development", "staging", "production", "test"],
    "FLASK_ENV": ["development", "production"],
    "APP_ENV": ["development", "staging", "production"],
    "PORT": None,  # Indicates any numeric value is a default
    "HOST": ["localhost", "0.0.0.0", "127.0.0.1"],
}


def _classify_variable(key: str, value: str) -> Tuple[bool, Any]:
    """
    Intelligently classifies a variable as a secret and suggests a default value.

    Returns:
        A tuple of (is_secret: bool, default_value: Any | None).
    """
    # 1. Check value against high-confidence secret patterns first
    for secret in SECRET_PATTERNS:
        if re.search(secret["pattern"], value):
            return True, None

    # 2. Check the key for common secret-indicating keywords
    key_lower = key.lower()
    for keyword in SECRET_KEY_KEYWORDS:
        if keyword in key_lower:
            return True, None

    # 3. Check for common non-secret patterns that are good candidates for default values
    if key in COMMON_NON_SECRETS:
        allowed_values = COMMON_NON_SECRETS[key]
        if allowed_values is None and value.isdigit():
            return False, value  # For PORT etc.
        if allowed_values and value.lower() in allowed_values:
            return False, value

    # 4. Default classification
    return False, None


def generate_schema_from_file(file_path: str, interactive: bool = False) -> str:
    """
    Reads an environment file and generates a TOML schema string, with an
    optional interactive mode for refinement.
    """
    if not os.path.exists(file_path):
        raise EnvShieldException(f"Input file not found at: {file_path}")

    parser = get_parser(file_path)
    if not parser:
        raise EnvShieldException(f"Could not find a suitable parser for '{file_path}'.")

    variables = parser.get_vars(file_path, get_values=True)

    schema_dict: Dict[str, Any] = {}
    secrets_found = 0
    defaults_found = 0

    console.print("\n[bold]Analyzing variables...[/bold]")

    for key, value in variables.items():
        is_secret, default_value = _classify_variable(key, value)

        if interactive:
            console.print(
                f"\nVariable [bold cyan]{key}[/bold cyan] = [dim]'{value}'[/dim]"
            )
            is_secret = questionary.confirm(
                "  Mark as a secret?", default=is_secret
            ).ask()
            if not is_secret:
                use_default = questionary.confirm(
                    f"  Use '{value}' as the default value?",
                    default=(default_value is not None),
                ).ask()
                if use_default:
                    default_value = value
                else:
                    default_value = None

        schema_dict[key] = {"description": "TODO: Add description."}
        if is_secret:
            schema_dict[key]["secret"] = True
            secrets_found += 1
        else:
            schema_dict[key]["secret"] = False
            if default_value is not None:
                schema_dict[key]["defaultValue"] = default_value
                defaults_found += 1

    header = (
        "# This schema was auto-generated by 'envshield import'\n"
        "# Please review and add descriptions for each variable.\n\n"
    )

    console.print("\n[bold green]âœ“ Analysis complete![/bold green]")
    console.print(f"- Processed {len(variables)} variables.")
    console.print(f"- Marked {secrets_found} variable(s) as secrets.")
    console.print(f"- Suggested {defaults_found} default value(s).")

    return header + toml.dumps(schema_dict)
